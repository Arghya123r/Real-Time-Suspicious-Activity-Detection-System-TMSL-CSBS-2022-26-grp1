{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip3 install torch torchvision pillow tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T11:20:05.081403Z",
     "iopub.status.busy": "2025-12-06T11:20:05.081174Z",
     "iopub.status.idle": "2025-12-06T11:20:05.231294Z",
     "shell.execute_reply": "2025-12-06T11:20:05.230182Z",
     "shell.execute_reply.started": "2025-12-06T11:20:05.081386Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!nvidia-smi --list-gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T11:20:05.232596Z",
     "iopub.status.busy": "2025-12-06T11:20:05.232327Z",
     "iopub.status.idle": "2025-12-06T11:20:12.306523Z",
     "shell.execute_reply": "2025-12-06T11:20:12.305938Z",
     "shell.execute_reply.started": "2025-12-06T11:20:05.232572Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "import glob\n",
    "from typing import List, Tuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torch.amp import GradScaler, autocast\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from typing import Optional, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T11:20:12.308618Z",
     "iopub.status.busy": "2025-12-06T11:20:12.308306Z",
     "iopub.status.idle": "2025-12-06T11:20:12.391431Z",
     "shell.execute_reply": "2025-12-06T11:20:12.390667Z",
     "shell.execute_reply.started": "2025-12-06T11:20:12.308601Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --------------- Config ---------------\n",
    "class Cfg:\n",
    "    dataset_root = \"/kaggle/input/training-processed/data/processed\"#<-- changes based on database location\n",
    "    train_manifest_csv = \"kaggle_train_manifest.csv\"\n",
    "    val_manifest_csv = \"kaggle_val_manifest.csv\"\n",
    "    # Sequence parameters\n",
    "    frames_per_sequence = 10\n",
    "    num_sequences = 6\n",
    "    sequence_overlap = 6\n",
    "    # Image processing\n",
    "    frame_size = 224\n",
    "    # Model parameters\n",
    "    backbone = \"resnet18\"\n",
    "    pretrained = True\n",
    "    freeze_cnn = True\n",
    "    lstm_hidden = 256\n",
    "    lstm_layers = 2\n",
    "    bidirectional = True\n",
    "    dropout = 0.2\n",
    "    # Training parameters\n",
    "    batch_size = 16\n",
    "    num_workers = 4\n",
    "    prefetch_factor = 2\n",
    "    pin_memory = True\n",
    "    epochs = 20\n",
    "    lr = 5e-4\n",
    "    weight_decay = 1e-5\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    # MIL parameters\n",
    "    use_mil = True\n",
    "    mil_margin = 0.5\n",
    "    topk = 3\n",
    "    clip_grad = 1.0\n",
    "    # Data split\n",
    "    train_split = 0.8\n",
    "    # AMP & scheduler\n",
    "    max_lr = 1e-3\n",
    "cfg = Cfg()\n",
    "print(\"Using: \", cfg.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T11:20:12.392792Z",
     "iopub.status.busy": "2025-12-06T11:20:12.392460Z",
     "iopub.status.idle": "2025-12-06T11:20:12.551288Z",
     "shell.execute_reply": "2025-12-06T11:20:12.550548Z",
     "shell.execute_reply.started": "2025-12-06T11:20:12.392761Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#-----------------Checkpointing Utilities----\n",
    "def save_checkpoint(state, filename=\"checkpoint.pt\"):\n",
    "    torch.save(state, filename)\n",
    "    print(f\"Checkpoint saved to {filename}\")\n",
    "\n",
    "def load_checkpoint(filename, model, optimizer=None, scaler=None, scheduler=None):\n",
    "    if not os.path.exists(filename):\n",
    "        print(\"No checkpoint found at\", filename)\n",
    "        return None\n",
    "    state = torch.load(filename, map_location=cfg.device, weights_only=False)\n",
    "    model.load_state_dict(state['model'])\n",
    "    if optimizer is not None and 'optimizer' in state:\n",
    "        optimizer.load_state_dict(state['optimizer'])\n",
    "    if scaler is not None and 'scaler' in state:\n",
    "        scaler.load_state_dict(state['scaler'])\n",
    "    if scheduler is not None and 'scheduler' in state:\n",
    "        scheduler.load_state_dict(state['scheduler'])\n",
    "    print(f\"Loaded checkpoint from {filename}, epoch {state['epoch']}, best={state.get('best', None)}\")\n",
    "    return state\n",
    "\n",
    "\n",
    "# --------------- Transforms ---------------\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize((cfg.frame_size, cfg.frame_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T11:20:12.552584Z",
     "iopub.status.busy": "2025-12-06T11:20:12.552252Z",
     "iopub.status.idle": "2025-12-06T11:20:12.572556Z",
     "shell.execute_reply": "2025-12-06T11:20:12.571848Z",
     "shell.execute_reply.started": "2025-12-06T11:20:12.552558Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --------------- Data Utilities ---------------\n",
    "def create_kaggle_manifests():\n",
    "    anomaly_classes = {\n",
    "        'Abuse','Arrest','Arson','Assault','Burglary','Explosion',\n",
    "        'Fighting','RoadAccidents','Robbery','Shooting','Shoplifting',\n",
    "        'Stealing','Vandalism'\n",
    "    }\n",
    "    normal_classes = {'Normal','Normal_Videos','normal'}\n",
    "    class_dirs = [d for d in os.listdir(cfg.dataset_root)\n",
    "                  if os.path.isdir(os.path.join(cfg.dataset_root, d))]\n",
    "    train_data, val_data = [], []\n",
    "    print(\"Processing Kaggle UCF-Crime dataset...\")\n",
    "    for class_name in class_dirs:\n",
    "        class_path = os.path.join(cfg.dataset_root, class_name)\n",
    "        if class_name in anomaly_classes:\n",
    "            label = 1\n",
    "        elif any(n.lower() in class_name.lower() for n in normal_classes):\n",
    "            label = 0\n",
    "        else:\n",
    "            label = 1\n",
    "            print(f\"Warning: Unknown class '{class_name}' assumed anomalous\")\n",
    "        all_images = []\n",
    "        for ext in ('*.jpg','*.jpeg','*.png','*.bmp'):\n",
    "            all_images.extend(glob.glob(os.path.join(class_path, ext)))\n",
    "        all_images.sort()\n",
    "        # group by video id\n",
    "        video_groups = defaultdict(list)\n",
    "        for p in all_images:\n",
    "            name = os.path.basename(p)\n",
    "            vid = '_'.join(name.split('_')[:-1]) if '_' in name else name.split('.')[0]\n",
    "            video_groups[vid].append(p)\n",
    "        seqs = []\n",
    "        step = cfg.frames_per_sequence - cfg.sequence_overlap\n",
    "        for frames in video_groups.values():\n",
    "            frames.sort()\n",
    "            for i in range(0, len(frames)-cfg.frames_per_sequence+1, step):\n",
    "                seqs.append(frames[i:i+cfg.frames_per_sequence])\n",
    "        if not seqs and len(all_images) >= cfg.frames_per_sequence:\n",
    "            for i in range(0, len(all_images)-cfg.frames_per_sequence+1, step):\n",
    "                seqs.append(all_images[i:i+cfg.frames_per_sequence])\n",
    "        random.shuffle(seqs)\n",
    "        split = int(len(seqs)*cfg.train_split)\n",
    "        for s in seqs[:split]:\n",
    "            train_data.append([';'.join(s), label])\n",
    "        for s in seqs[split:]:\n",
    "            val_data.append([';'.join(s), label])\n",
    "        print(f\"  {class_name}: {len(all_images)} images -> {split} train, {len(seqs)-split} val\")\n",
    "    for fname, data in [(cfg.train_manifest_csv, train_data),\n",
    "                        (cfg.val_manifest_csv, val_data)]:\n",
    "        with open(fname, 'w', newline='') as f:\n",
    "            w = csv.writer(f)\n",
    "            w.writerow(['frame_paths','label'])\n",
    "            w.writerows(data)\n",
    "    print(f\"Manifests created: {len(train_data)} train, {len(val_data)} val\")\n",
    "    return len(train_data), len(val_data)\n",
    "\n",
    "class KaggleFrameDataset(Dataset):\n",
    "    def __init__(self, manifest_csv):\n",
    "        self.items = []\n",
    "        with open(manifest_csv, newline='') as f:\n",
    "            for row in csv.DictReader(f):\n",
    "                paths = row['frame_paths'].split(';')\n",
    "                self.items.append((paths, int(row['label'])))\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "    def __getitem__(self, idx):\n",
    "        paths, label = self.items[idx]\n",
    "        frames = []\n",
    "        for p in paths:\n",
    "            try:\n",
    "                img = Image.open(p).convert('RGB')\n",
    "                frames.append(img_transform(img))\n",
    "            except:\n",
    "                frames.append(torch.zeros(3, cfg.frame_size, cfg.frame_size))\n",
    "        bag = torch.stack(frames).unsqueeze(0)  # (1, F, C, H, W)\n",
    "        return bag, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "def collate_frame_bags(batch):\n",
    "    bags, labels = zip(*batch)\n",
    "    return torch.stack(bags), torch.stack(labels)\n",
    "\n",
    "from typing import Optional, List\n",
    "\n",
    "def format_lrs(optimizer, scheduler: Optional[object] = None, mode: str = \"all\") -> str:\n",
    "    \"\"\"\n",
    "    Build a display string for current LR(s).\n",
    "    mode: \"first\" -> first group's lr; \"mean\" -> mean across groups; \"all\" -> join all.\n",
    "    \"\"\"\n",
    "    # Collect current LRs as a list of floats\n",
    "    if scheduler is not None and hasattr(scheduler, \"get_last_lr\"):\n",
    "        lrs: List[float] = list(scheduler.get_last_lr())\n",
    "    else:\n",
    "        lrs = [pg[\"lr\"] for pg in optimizer.param_groups]\n",
    "\n",
    "    if not lrs:  # safety\n",
    "        return \"n/a\"\n",
    "\n",
    "    if mode == \"first\" or len(lrs) == 1:\n",
    "        return f\"{lrs[0]:.2e}\"  # Access first element, not the entire list\n",
    "    elif mode == \"mean\":\n",
    "        return f\"{(sum(lrs) / len(lrs)):.2e}\"\n",
    "    elif mode == \"all\":\n",
    "        return \" / \".join(f\"{v:.2e}\" for v in lrs)\n",
    "    else:\n",
    "        return f\"{lrs[0]:.2e}\"  # Fallback to first element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T11:20:12.573405Z",
     "iopub.status.busy": "2025-12-06T11:20:12.573205Z",
     "iopub.status.idle": "2025-12-06T11:20:12.592796Z",
     "shell.execute_reply": "2025-12-06T11:20:12.592194Z",
     "shell.execute_reply.started": "2025-12-06T11:20:12.573390Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --------------- Model ---------------\n",
    "class LRCN(nn.Module):\n",
    "    def __init__(self, backbone='resnet18', pretrained=True,\n",
    "                 lstm_hidden=256, lstm_layers=1, bidirectional=False,\n",
    "                 dropout=0.3, freeze_cnn=False):\n",
    "        super().__init__()\n",
    "        if cfg.backbone=='resnet18':\n",
    "            net = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1 if cfg.pretrained else None)\n",
    "            feat_dim=512\n",
    "            print(\"Using resnet18\")\n",
    "        else:\n",
    "            net = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1 if cfg.pretrained else None)\n",
    "            feat_dim=2048\n",
    "        self.cnn = nn.Sequential(*list(net.children())[:-1])\n",
    "        net.to(cfg.device)\n",
    "        if cfg.freeze_cnn:\n",
    "            for p in self.cnn.parameters(): p.requires_grad=False\n",
    "            print(\"CNN Frozen\")\n",
    "        self.lstm = nn.LSTM(input_size=feat_dim, hidden_size=cfg.lstm_hidden,\n",
    "                            num_layers=cfg.lstm_layers, batch_first=True,\n",
    "                            bidirectional=cfg.bidirectional,\n",
    "                            dropout=0.0 if cfg.lstm_layers==1 else cfg.dropout)\n",
    "        out_dim = cfg.lstm_hidden*(2 if cfg.bidirectional else 1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(cfg.dropout),\n",
    "            nn.Linear(out_dim,128), nn.ReLU(inplace=True),\n",
    "            nn.Linear(128,1)\n",
    "        )\n",
    "    #def forward(self, bag):\n",
    "    #    B,S,F,C,H,W = bag.shape\n",
    "    #    x = bag.view(B*S*F,C,H,W)\n",
    "    #    feats = self.cnn(x).view(B,S,F,-1)\n",
    "    #    logits=[]\n",
    "    #    for s in range(S):\n",
    "    #        seq = feats[:,s]\n",
    "    #        lstm_out,_=self.lstm(seq)\n",
    "    #        pooled=lstm_out[:,-1]\n",
    "    #        logits.append(self.classifier(pooled).squeeze(-1))\n",
    "    #    return torch.stack(logits,1)\n",
    "    def forward(self,bag):\n",
    "        B,S,F,C,H,W = bag.shape\n",
    "        x = bag.view(B*S*F,C,H,W)\n",
    "        feats = self.cnn(x)\n",
    "        \n",
    "        feat_dim = feats.shape[1]\n",
    "        feats = feats.view(B,S*F,feat_dim)\n",
    "        \n",
    "        lstm_out, _ = self.lstm(feats)\n",
    "        pooled = lstm_out[:,-1,:]\n",
    "        \n",
    "        logits = self.classifier(pooled)\n",
    "        \n",
    "        return logits\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "def aggregate_video_score(seg_logits, mode=\"mean\", k=1):\n",
    "    if mode == \"max\":\n",
    "        v, _ = seg_logits.max(dim=1)\n",
    "    elif mode == \"mean\":\n",
    "        v = seg_logits.mean(dim=1)\n",
    "    elif mode == \"topk\":\n",
    "        k = max(1, min(k, seg_logits.shape[1]))\n",
    "        v, _ = torch.topk(seg_logits, k=k, dim=1)\n",
    "        v = v.mean(dim=1)\n",
    "    return v\n",
    "\n",
    "def mil_ranking_loss(pos_seg, neg_seg, margin=1.0, topk=1):\n",
    "    k = max(1, min(topk, pos_seg.shape[1], neg_seg.shape[1]))\n",
    "    pos_top, _ = torch.topk(pos_seg, k=k, dim=1)\n",
    "    neg_top, _ = torch.topk(neg_seg, k=k, dim=1)\n",
    "    pos_score = pos_top.mean(dim=1).unsqueeze(1)\n",
    "    neg_score = neg_top.mean(dim=1).unsqueeze(0)\n",
    "    loss = F.relu(margin - pos_score + neg_score).mean()\n",
    "    return loss\n",
    "\n",
    "def train_epoch(model, loader, optimizer, scaler, scheduler=None, epoch: int = 0):\n",
    "    model.train()\n",
    "    running = 0.0\n",
    "    bce = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    pbar = tqdm(enumerate(loader),\n",
    "                total=len(loader),\n",
    "                desc=f\"Epoch {epoch}\",\n",
    "                dynamic_ncols=True)\n",
    "\n",
    "    for i, (bags, labels) in pbar:\n",
    "        bags, labels = bags.to(cfg.device), labels.float().to(cfg.device)\n",
    "\n",
    "        with autocast(cfg.device):\n",
    "            optimizer.zero_grad()\n",
    "            seg_logits = model(bags)\n",
    "            if cfg.use_mil:\n",
    "                pos = labels == 1\n",
    "                neg = labels == 0\n",
    "                loss = torch.tensor(0.0, device=cfg.device)\n",
    "                if pos.any() and neg.any():\n",
    "                    loss += mil_ranking_loss(seg_logits[pos], seg_logits[neg], cfg.mil_margin, cfg.topk)\n",
    "                vids = aggregate_video_score(seg_logits, mode=\"topk\", k=cfg.topk)\n",
    "                loss += bce(vids, labels)\n",
    "            else:\n",
    "                vids = aggregate_video_score(seg_logits, mode=\"topk\", k=cfg.topk)\n",
    "                loss = bce(vids, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.clip_grad)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        running += loss.item() * bags.size(0)\n",
    "\n",
    "        # update tqdm postfix with current/avg loss and LR\n",
    "        lr_str = format_lrs(optimizer, scheduler, mode = \"mean\")\n",
    "        avg_loss = running / ((i + 1) * bags.size(0))\n",
    "        pbar.set_postfix(loss=f\"{loss.item():.4f}\", avg=f\"{avg_loss:.4f}\", lr=lr_str)\n",
    "    del vids\n",
    "    del loss\n",
    "\n",
    "    return running / len(loader.dataset)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    all_s,all_l=[],[]\n",
    "    for bags,labels in loader:\n",
    "        bags=bags.to(cfg.device)\n",
    "        seg_logits=model(bags)\n",
    "        vids=torch.sigmoid(aggregate_video_score(seg_logits,\"topk\",cfg.topk))\n",
    "        all_s.append(vids.cpu()); all_l.append(labels)\n",
    "    scores=torch.cat(all_s).numpy(); labels=torch.cat(all_l).numpy()\n",
    "    predictions = (scores >= 0.5).astype(int)\n",
    "\n",
    "    from sklearn.metrics import roc_auc_score,f1_score,recall_score,precision_score,accuracy_score\n",
    "    return {\"AUC\":roc_auc_score(labels,scores),\"ACC\":accuracy_score(labels,predictions),\"F1\":f1_score(labels,predictions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-12-06T13:03:25.120Z",
     "iopub.execute_input": "2025-12-06T11:20:12.593804Z",
     "iopub.status.busy": "2025-12-06T11:20:12.593554Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    if not (os.path.exists(cfg.train_manifest_csv) and os.path.exists(cfg.val_manifest_csv)):\n",
    "        create_kaggle_manifests()\n",
    "\n",
    "    train_ds=KaggleFrameDataset(cfg.train_manifest_csv)\n",
    "    val_ds=KaggleFrameDataset(cfg.val_manifest_csv)\n",
    "    train_loader=DataLoader(train_ds,batch_size=cfg.batch_size,shuffle=True,\n",
    "                            num_workers=cfg.num_workers,pin_memory=cfg.pin_memory,\n",
    "                            prefetch_factor=cfg.prefetch_factor,collate_fn=collate_frame_bags)\n",
    "    val_loader=DataLoader(val_ds,batch_size=cfg.batch_size,shuffle=False,\n",
    "                          num_workers=cfg.num_workers,pin_memory=cfg.pin_memory,\n",
    "                          prefetch_factor=cfg.prefetch_factor,collate_fn=collate_frame_bags)\n",
    "\n",
    "    model=LRCN(backbone=cfg.backbone, pretrained=cfg.pretrained,\n",
    "                lstm_hidden=cfg.lstm_hidden, lstm_layers=cfg.lstm_layers,\n",
    "                bidirectional=cfg.bidirectional, dropout=cfg.dropout,\n",
    "                freeze_cnn=cfg.freeze_cnn)\n",
    "    if torch.cuda.device_count()>1:\n",
    "        model=nn.DataParallel(model,device_ids = [0,1])\n",
    "    model.to(cfg.device)\n",
    "    optimizer=torch.optim.AdamW(model.parameters(),lr=cfg.lr,weight_decay=cfg.weight_decay)\n",
    "    scaler=GradScaler()\n",
    "    scheduler=OneCycleLR(optimizer,max_lr=cfg.max_lr,\n",
    "                        steps_per_epoch=len(train_loader),epochs=cfg.epochs)\n",
    "\n",
    "    start_epoch = 1\n",
    "    best = -1\n",
    "    checkpoint_file = \"checkpoint.pt\"\n",
    "    if os.path.exists(checkpoint_file):\n",
    "        state = load_checkpoint(checkpoint_file, model, optimizer, scaler, scheduler)\n",
    "        if state:\n",
    "            start_epoch = state['epoch'] + 1\n",
    "            best = state.get('best', best)\n",
    "\n",
    "    for epoch in range(start_epoch,cfg.epochs+1):\n",
    "        print(\"Training Epoch Started.\")\n",
    "        loss=train_epoch(model,train_loader,optimizer,scaler,scheduler,epoch)\n",
    "        mets=evaluate(model,val_loader)\n",
    "        print(f\"Epoch {epoch:2d} | Loss: {loss:.4f} | \" +\" \".join(f\"{k}:{v:.4f}\" for k,v in mets.items()))\n",
    "        score=mets.get(\"AUC\",mets.get(\"ACC\",0))\n",
    "        if score>best:\n",
    "            best=score\n",
    "            torch.save(model.state_dict(),\"lrcn_ucf_best.pt\")\n",
    "            print(f\"  -> New best: {best:.4f}\")\n",
    "            \n",
    "        csv_filename = \"metrics_1.csv\"\n",
    "        fieldnames = [\"Epoch\", \"Loss\", \"AUC\", \"ACC\",\"F1\"]\n",
    "\n",
    "# Check if file exists to write header\n",
    "        file_exists = os.path.exists(csv_filename)\n",
    "\n",
    "        with open(csv_filename, mode='a', newline='') as file:\n",
    "            writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    \n",
    "            if not file_exists:\n",
    "                writer.writeheader()\n",
    "    \n",
    "    # Inside the training loop\n",
    "            row = {\n",
    "                \"Epoch\": epoch,\n",
    "                \"Loss\": loss,\n",
    "                \"AUC\": mets[\"AUC\"],\n",
    "                \"ACC\": mets[\"ACC\"],\n",
    "                \"F1\": mets[\"F1\"]\n",
    "            }\n",
    "            writer.writerow(row)\n",
    "\n",
    "        save_checkpoint({\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'scaler': scaler.state_dict(),\n",
    "            'scheduler': scheduler.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'best': best\n",
    "        })\n",
    "        del loss\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7898434,
     "sourceId": 12513577,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
